---
title: "Group A Project 2"
author: "Jerome Dennis Kaypee"
date: "4 July 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}

library(plyr)
library(dplyr)
library(ggplot2)
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install()
BiocManager::install(c("Rgraphviz", "graph"))

if (!require("pacman")) install.packages("pacman")
pacman::p_load_gh("trinker/textstem")
pacman::p_load(textstem, dplyr)
library(tm) 
library(SnowballC)

df<- read.csv("F:/Big Data Analytics YorkU/Course 5/Project 2/st_tweets.csv")

View(df)

StrTngCorpus <- Corpus(VectorSource(df$text))

StrTngCorpus <- tm_map(StrTngCorpus, tolower)

StrTngCorpus <- tm_map(StrTngCorpus,PlainTextDocument)

# remove punctuation
StrTngCorpus <- tm_map(StrTngCorpus, removePunctuation)
# remove numbers
StrTngCorpus <- tm_map(StrTngCorpus, removeNumbers)
# remove http*
toSpace = content_transformer( function(x, pattern) gsub(pattern,"",x) )
StrTngCorpus = tm_map( StrTngCorpus, toSpace, "https.*")

library(textstem)
lemmatize_words(StrTngCorpus)

library(stopwords)
strTngStopwords <- c(stopwords(language="en", source="smart"), "available", "via", "the")

StrTngCorpus <- tm_map(StrTngCorpus, stripWhitespace)
StrTngCorpus <- tm_map(StrTngCorpus, removeWords, strTngStopwords)


#StrTngStemCorpus<-StrTngCorpus
#StrTngStemCorpus <- tm_map(StrTngStemCorpus, stemDocument)
inspect(StrTngStemCorpus[1:3])

remWords<-c('stranger','thing','season','premier', 'stranger thing season premier')

StrTngCorpus <- tm_map(StrTngCorpus, removeWords, remWords)


inspect(StrTngStemCorpus[1:3])


library(textstem)
lemmatize_words(StrTngCorpus)

strTngDM <- TermDocumentMatrix(StrTngCorpus, control = list(minWordLength = 1))
#View(strTngDM)

rowTotals <- apply(strTngDM , 1, sum) #Find the sum of words in each Document
strTngDM <- strTngDM[rowTotals > 0, ] #remove all docs without words

#Based on the above matrix, many data mining tasks can be done, 
#for example, clustering, classification and association analysis.

#Frequent Terms and Association
freq.terms <- findFreqTerms(strTngDM, lowfreq=5)

term.freq <- rowSums(as.matrix(strTngDM))
term.freq <- subset(term.freq, term.freq >= 5)
strTngdf <- data.frame(term = names(term.freq), freq = term.freq)

View(strTngdf)

library(ggplot2)
ggplot(strTngdf, aes(x = 'term', y = 'freq')) + geom_bar(stat = "identity") +
xlab("Terms") + ylab("Count") + coord_flip()

source("https://bioconductor.org/biocLite.R")
biocLite("Rgraphviz")
library(graph)
library(Rgraphviz)
plot(strTngDM)#, term = freq.terms, corThreshold = 0.1, weighting = T)

library(wordcloud)
strTngMTX <- as.matrix(strTngDM)

# calculate the frequency of words and sort it by frequency
word.freq <- sort(rowSums(strTngMTX), decreasing = T)
# colors
pal <- brewer.pal(9, "BuGn")
pal <- pal[-(1:4)]

# plot word cloud
wordcloud(words = names(word.freq), freq = word.freq, min.freq = 200,
random.order = F, colors = pal)

strTngDM2 <- removeSparseTerms(strTngDM, sparse = 0.98)
strTngMTX2 <- as.matrix(strTngDM2)
# cluster terms
distMatrix <- dist(scale(strTngMTX2))
fit <- hclust(distMatrix, method = "ward.D")

plot(fit)
rect.hclust(fit, k = 6) # cut tree into 9 clusters

dtm <- as.DocumentTermMatrix(strTngDM)
ui = unique(dtm$i)
dtm.new = dtm[ui,]
tweets.df.new = df[ui,]
library(topicmodels)
lda <- LDA(dtm.new, k = 10) # find 10 topics
(term <- terms(lda, 10)) # first 10 terms of every topic

topic <- topics(lda, 1)
library(data.table)
topics <- data.frame(date=as.IDate(tweets.df.new$created), topic)

qplot(date, ..count.., data=topics, geom="density",
fill=term[topic], position="stack")

require(devtools)
install_github("sentiment140", "okugami79")

library(sentimentr)
df$text<-as.character(df$text)
sentiments <- sentiment_by(df$text)
sentiments <- as.data.frame(sentiments)
View(sentiments)
plot(sentiments)

colnames(sentiments)=c("score")
sentiments$date <- as.IDate(df$created)
result <- aggregate(score ~ date, data = sentiments, sum)
plot(result, type = "l")

```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
